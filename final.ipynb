{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings\n",
    "ROTATE_IMAGE = False\n",
    "\n",
    "PLOT_UNIQUE_INTENSITIES = False\n",
    "PLOT_IMAGE_INITIAL = True\n",
    "PLOT_NORMALISED_HIST = True\n",
    "\n",
    "CLIP_DATA = True\n",
    "\n",
    "NORMALISE_AUTOCORRELATION = False\n",
    "CLIP_DATA_3DPLOT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit, curve_fit, minimize_scalar\n",
    "from scipy import signal\n",
    "from scipy.special import spherical_jn\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paths to image source files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_list = [\n",
    "    r\"C:\\Users\\GAdmin\\Desktop\\srp\\Hemanya and Sujen\\speckle pictures june 13\\with iris\\001.csv\",\n",
    "    # r\"C:\\Users\\GAdmin\\Desktop\\srp\\Hemanya and Sujen\\speckle pictures june 13\\with iris\\002.csv\",\n",
    "    # r\"C:\\Users\\GAdmin\\Desktop\\srp\\Hemanya and Sujen\\speckle pictures june 13\\with iris\\003.csv\",\n",
    "    # r\"C:\\Users\\GAdmin\\Desktop\\srp\\Hemanya and Sujen\\speckle pictures june 13\\with iris\\004.csv\",\n",
    "    # r\"C:\\Users\\GAdmin\\Desktop\\srp\\Hemanya and Sujen\\speckle pictures june 13\\with iris\\005.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_list = []\n",
    "\n",
    "def get_pics(source_list):\n",
    "    for source in source_list:\n",
    "        data = pd.read_csv(source, header=None, delimiter=r\"\\s+\").to_numpy()\n",
    "        pic_list.append(data)\n",
    "\n",
    "    return pic_list\n",
    "\n",
    "pic_list = get_pics(source_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#camera stuff\n",
    "sensor_size = pic_list[0].shape\n",
    "print(sensor_size)\n",
    "\n",
    "#rotational transform of matrix to compensate for bending of lens\n",
    "if ROTATE_IMAGE:\n",
    "    from skimage.transform import rotate\n",
    "    rotation_angle = -30\n",
    "    im_matrix_4_rotated = rotate(im_matrix_4, rotation_angle)\n",
    "    plt.imshow(im_matrix_4)\n",
    "    plt.show()\n",
    "    plt.imshow(im_matrix_4_rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot images, hist, hist-normalised for all pictures\n",
    "def plot_images_and_histograms(pic_list):\n",
    "    for i, im_matrix in enumerate(pic_list):\n",
    "\n",
    "        #image\n",
    "        if PLOT_IMAGE_INITIAL:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            im = plt.imshow(im_matrix, cmap='gray', aspect='auto')\n",
    "            plt.title(f\"image - {i+1}\")\n",
    "            plt.colorbar(im)\n",
    "\n",
    "        #hist\n",
    "        if PLOT_UNIQUE_INTENSITIES:\n",
    "            unique_intensities, counts = np.unique(im_matrix.flatten(), return_counts=True)\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.scatter(unique_intensities, counts, s=2)\n",
    "            plt.title(f\"hist - Image {i+1}\")\n",
    "            plt.xlabel(\"value\")\n",
    "            plt.ylabel(\"frequency\")\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "        #hist-normalised\n",
    "        if PLOT_NORMALISED_HIST:\n",
    "            counts, bins = np.histogram(im_matrix, bins=100)\n",
    "            bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.bar(bin_centers, counts/counts.max(), width=np.diff(bins), align='center', edgecolor='black')\n",
    "            plt.title(f\"normalised hist - Image {i+1}\")\n",
    "            plt.xlabel(\"value\")\n",
    "            plt.ylabel(\"frequency\")\n",
    "            plt.grid(True)\n",
    "            plt.scatter(bin_centers, counts/counts.max(), c='orange', marker='x', label='Counts')\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "plot_images_and_histograms(pic_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below - probability density function on the intensity of points. will extract $\\bar{I}$ from fitting this equation\n",
    "$$\n",
    "p_I(I)= \\frac{1}{\\bar{I}}\\cdot e^{-\\frac{I}{\\bar{I}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf intensity\n",
    "def intensity_probability_curve(x_o, a, b, c):\n",
    "    return (1/(a)) * np.exp(-(x_o - b) / (a) + c)\n",
    "\n",
    "def curve_fitting_pics(pic_list):\n",
    "    highest_intensity_recorded = 80 * 10**-6\n",
    "    area_of_pixel = 8.1 * 10**-11\n",
    "    \n",
    "    for i, im_matrix in enumerate(pic_list):\n",
    "        #normalise intensity to highest value recorded\n",
    "        highest_pixel_density = np.max(im_matrix)\n",
    "        normalisation_factor = (highest_intensity_recorded / highest_pixel_density) * 1 / area_of_pixel\n",
    "\n",
    "        #finding unique intensity values with counts\n",
    "        unique_intensities, counts = np.unique(im_matrix.flatten(), return_counts=True)\n",
    "\n",
    "        #binning\n",
    "        counts_hist, bins = np.histogram(im_matrix, bins=100)\n",
    "        bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "        bin_centers_normalised = bin_centers * normalisation_factor\n",
    "\n",
    "        #fitting\n",
    "        fitted_parameters, cov = curve_fit(intensity_probability_curve, bin_centers, counts_hist / counts_hist.max(), p0=[174, 159, 4.11])\n",
    "        a, b, c = fitted_parameters\n",
    "\n",
    "        large_range_of_X_values = np.arange(0, np.max(bin_centers), 0.1)\n",
    "        generated_y_values = intensity_probability_curve(large_range_of_X_values, a, b, c)\n",
    "        \n",
    "\n",
    "        if not CLIP_DATA:\n",
    "            #plot with fit, initial data, normalised\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.bar(bin_centers_normalised, counts_hist / counts_hist.max(), width=np.diff(bins) * normalisation_factor, align='center', edgecolor='black')\n",
    "            plt.plot(large_range_of_X_values * normalisation_factor, generated_y_values, label='Fitted Curve')\n",
    "            plt.scatter(bin_centers_normalised, counts_hist / counts_hist.max(), c='orange', marker='x', label='Counts')\n",
    "            plt.xlabel('Intensity per square meter')\n",
    "            plt.ylabel('Counts / Intensity Probability')\n",
    "            plt.title(f'Curve Fitting on Histogram Data - Image {i+1}')\n",
    "            plt.text(0.5, 0.5, f\"Fitted average intensity: {np.round(a * normalisation_factor, 2)}\\nHorizontal offset value: {np.round(b * normalisation_factor, 2)}\\nVertical offset value: {np.round(c, 2)}\", transform=plt.gca().transAxes)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            #clip points less than max\n",
    "            position_of_largest_value = np.argmax(counts_hist)\n",
    "            counts_new = np.delete(counts_hist, range(0, position_of_largest_value))\n",
    "            bin_centers_new = np.delete(bin_centers, range(0, position_of_largest_value))\n",
    "\n",
    "            #second curve fitting without initial data points\n",
    "            fitted_parameters_new, cov_new = curve_fit(intensity_probability_curve, bin_centers_new, counts_new / counts_hist.max(), p0=[170, -800, 4.0])\n",
    "            A, B, C = fitted_parameters_new\n",
    "\n",
    "            #y-values for the new fitted curve\n",
    "            large_range_of_X_values_new = np.arange(bin_centers_new[0], np.max(bin_centers_new), 0.1)\n",
    "            generated_y_values_new = intensity_probability_curve(large_range_of_X_values_new, A, B, C)\n",
    "\n",
    "            #new normalized histogram with new curve fit\n",
    "            plt.bar(bin_centers_new * normalisation_factor, counts_new / counts_hist.max(), width=np.diff(bins[position_of_largest_value:]) * normalisation_factor, align='center', edgecolor='black')\n",
    "            plt.plot(large_range_of_X_values_new * normalisation_factor, generated_y_values_new, label='Fitted Curve', c='red')\n",
    "            plt.scatter(bin_centers_new * normalisation_factor, counts_new / counts_hist.max(), c='orange', marker='x', label='Counts')\n",
    "            plt.xlabel('Intensity per square meter')\n",
    "            plt.ylabel('Counts / Intensity Probability')\n",
    "            plt.title(f'Curve Fitting on Histogram Data after Removing Initial Data - Image {i+1}')\n",
    "            plt.text(0.5, 0.5, f\"Fitted average intensity: {np.round(A * normalisation_factor, 2)}\\nHorizontal offset value: {np.round(B * normalisation_factor, 2)}\\nVertical offset value: {np.round(C, 2)}\", transform=plt.gca().transAxes)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "curve_fitting_pics(pic_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bessel function which we will fit onto the data.\n",
    "$$\n",
    "\\Gamma_1(r)= \\bar{I}^2 \\left[ 1 + \\left|\\left(2\\frac{J_1\\frac{\\pi D r}{\\lambda z}}{\\frac{\\pi D r}{\\lambda z}}\\right)\\right|^2 \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vertical coeff offset - account for stray light\n",
    "def bessel_function(distance_dist, I_ave, B, A, C):\n",
    "    return (I_ave**2) * (1 + ((2 * B * spherical_jn(0, A * distance_dist)) / A)**2) + C\n",
    "\n",
    "def correlation(pic_list):\n",
    "    for i, im_matrix in enumerate(pic_list):\n",
    "\n",
    "        #compute autocorrelation\n",
    "        correlation = signal.correlate(im_matrix, im_matrix)\n",
    "        correlation_dist_x = signal.correlation_lags(len(im_matrix), len(im_matrix))\n",
    "        correlation_dist_y = signal.correlation_lags(624, 624)\n",
    "        L, B = np.shape(correlation)\n",
    "        \n",
    "        #finding midpoint\n",
    "        correlation_plotted_X = correlation[::1, int(((B + 1) / 2) - 1)]\n",
    "        correlation_plotted_y = correlation[int(((L + 1) / 2) + 1), ::1]\n",
    "\n",
    "        if NORMALISE_AUTOCORRELATION:\n",
    "            correlation_plotted_X /= np.max(correlation_plotted_X)\n",
    "            correlation_plotted_y /= np.max(correlation_plotted_y)\n",
    "        \n",
    "        # Plot autocorrelation in the x-axis\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(correlation_dist_x, correlation_plotted_X, label='autocorrelation - x', s=2)\n",
    "        plt.grid(True); plt.legend(); plt.ylabel(\"Autocorrelation\"); plt.xlabel(\"Distance \"); plt.title(f\"Graph of autocorrelation against distance  - image {i + 1} (x axis)\")\n",
    "        \n",
    "        #autocorrelation in the y-axis\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(correlation_dist_y, correlation_plotted_y, label='autocorrelation - y', s=1)\n",
    "        plt.grid(True); plt.legend() ;plt.ylabel(\"Autocorrelation\") ;plt.xlabel(\"Distance \")  ;plt.title(f\"Graph of autocorrelation against Distance  - image {i + 1} (y axis)\") ;plt.show()\n",
    "\n",
    "        #modifying distance and autocorrelation arrays - finds the max value of autocorrelation function and extracts the surrounding values in the vicinity\n",
    "        max_value_autocorrelation  = np.max(correlation_plotted_X)\n",
    "        max_value_autocorrelation_pos = np.where(correlation_plotted_X == max_value_autocorrelation) \n",
    "        max_value_autocorrelation_pos = int(max_value_autocorrelation_pos[0])\n",
    "        correlation_plotted_X_fit = correlation_plotted_X[max_value_autocorrelation_pos-7:max_value_autocorrelation_pos+8]\n",
    "        correlation_dist_x_fit = correlation_dist_x[max_value_autocorrelation_pos-7:max_value_autocorrelation_pos+8]\n",
    "\n",
    "        #fit bessel func and plot\n",
    "        p0 = [2.2449*10**2, 3.57615*10**2, -1.771, 8.623*10**9]\n",
    "        Fitted_parameters_autocorrelation, _ = curve_fit(bessel_function, correlation_dist_x_fit, correlation_plotted_X_fit, p0=p0)\n",
    "        I_ave, B, A, C = Fitted_parameters_autocorrelation\n",
    "        print(I_ave)\n",
    "\n",
    "        large_number_X_values_autocorrelation = np.arange(np.min(correlation_dist_x_fit), np.max(correlation_dist_x_fit), 0.0001)\n",
    "        fitted_autocorrelation_values = bessel_function(large_number_X_values_autocorrelation, I_ave, B, A, C)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(large_number_X_values_autocorrelation, fitted_autocorrelation_values, c='blue', label='Fitted Bessel Function')\n",
    "        plt.scatter(correlation_dist_x_fit, correlation_plotted_X_fit, c='orange', label='Autocorrelation')\n",
    "        plt.grid(True); plt.legend(); plt.ylabel(\"Autocorrelation\"); plt.xlabel(\"Distance \"); plt.title(f\"Graph of autocorrelation against distance  - image {i + 1} (x axis)\"); plt.show()\n",
    "\n",
    "        #extracting relevant parameters, adding y coeff offset to the bessel function (find fwhm)\n",
    "        fitted_autocorrelation_values_analyse = fitted_autocorrelation_values - C\n",
    "        max_value = np.max(fitted_autocorrelation_values_analyse)\n",
    "        half_max_value = max_value/2\n",
    "        tolerance = 1000000\n",
    "        half_max_values = np.where(np.abs(fitted_autocorrelation_values_analyse - half_max_value) < tolerance)[0]\n",
    "        half_max_value_neg = half_max_values[0]\n",
    "        half_max_value_pos = half_max_values[len(half_max_values) - 1]\n",
    "        fwhm = large_number_X_values_autocorrelation[half_max_value_pos] - large_number_X_values_autocorrelation[half_max_value_neg]\n",
    "\n",
    "        #minimum point and finding autocorr length\n",
    "        minimum_point_neg = minimize_scalar(lambda x: bessel_function(x, I_ave, B, A, C), bounds=(-3, 0))\n",
    "        minimum_point_pos = minimize_scalar(lambda x: bessel_function(x, I_ave, B, A, C), bounds=(0, 3))\n",
    "        autocorrelation_length = np.round(minimum_point_pos.x - minimum_point_neg.x, 3)\n",
    "\n",
    "        #final function with the measurements\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(large_number_X_values_autocorrelation, fitted_autocorrelation_values_analyse, label='fitted bessel function')\n",
    "        plt.scatter(minimum_point_pos.x, bessel_function(minimum_point_pos.x, I_ave, B, A, C) - C, label='left min point')\n",
    "        plt.scatter(minimum_point_neg.x, bessel_function(minimum_point_neg.x, I_ave, B, A, C) - C, label='right min point')\n",
    "        print(\"autocorrelation length: \", autocorrelation_length); print(\"FWHM: \", fwhm)\n",
    "        plt.grid(True); plt.legend(); plt.ylabel(\"Autocorrelation\"); plt.xlabel(\"Distance \"); plt.title(f\"Graph of autocorrelation against distance  - image {i + 1} (x axis)\"); plt.show()\n",
    "\n",
    "        #correlation matrix\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(correlation)\n",
    "        plt.title(f\"Correlation Matrix - Image {i + 1}\")\n",
    "        plt.colorbar() ;plt.show()\n",
    "\n",
    "        #3d plot of overall autocorrelation\n",
    "        if CLIP_DATA_3DPLOT:\n",
    "            clip = 600\n",
    "            correlation_dist_x = correlation_dist_x[len(correlation_dist_x) // 2 - clip: len(correlation_dist_x) // 2 + clip]\n",
    "            correlation_dist_y = correlation_dist_y[len(correlation_dist_y) // 2 - clip: len(correlation_dist_y) // 2 + clip]\n",
    "            correlation_plotted_X = correlation_plotted_X[len(correlation_plotted_X) // 2 - clip: len(correlation_plotted_X) // 2 + clip]\n",
    "            correlation_plotted_y = correlation_plotted_y[len(correlation_plotted_y) // 2 - clip: len(correlation_plotted_y) // 2 + clip]\n",
    "\n",
    "        X, Y = np.meshgrid(correlation_dist_x, correlation_dist_y)\n",
    "        autocorr2d = np.outer(correlation_plotted_X, correlation_plotted_y)\n",
    "        fig = plt.figure(figsize=(10, 7))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        surface = ax.plot_surface(X, Y, autocorr2d.T, cmap='viridis', edgecolor='none')\n",
    "        ax.set_title('autocorrelation')\n",
    "        ax.set_xlabel('X-axis')\n",
    "        ax.set_ylabel('Y-axis')\n",
    "        ax.set_zlabel('Autocorrelation')\n",
    "        fig.colorbar(surface, ax=ax, shrink=0.5, aspect=5, label='Autocorrelation')\n",
    "        plt.show()\n",
    "\n",
    "correlation(pic_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
